from lxml import etree
import time
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.183 Safari/537.36','Cookie': 'uuid=440a8506-cc13-4f32-810a-e1c0c1a9d184; ganji_uuid=1204183116227230798211; lg=1; antipas=2g04F7JD552l9322r0Bw9u659z12; cityDomain=cs; clueSourceCode=%2A%2300; user_city_id=204; preTime=%7B%22last%22%3A1604804930%2C%22this%22%3A1604630080%2C%22pre%22%3A1604630080%7D; sessionid=0d9d2a8b-da82-486a-9a7e-0853a22d0704; Hm_lvt_bf3ee5b290ce731c7a4ce7a617256354=1604630082,1604804930; Hm_lpvt_bf3ee5b290ce731c7a4ce7a617256354=1604804930; cainfo=%7B%22ca_a%22%3A%22-%22%2C%22ca_b%22%3A%22-%22%2C%22ca_s%22%3A%22self%22%2C%22ca_n%22%3A%22self%22%2C%22ca_medium%22%3A%22-%22%2C%22ca_term%22%3A%22-%22%2C%22ca_content%22%3A%22-%22%2C%22ca_campaign%22%3A%22-%22%2C%22ca_kw%22%3A%22-%22%2C%22ca_i%22%3A%22-%22%2C%22scode%22%3A%22-%22%2C%22keyword%22%3A%22-%22%2C%22ca_keywordid%22%3A%22-%22%2C%22display_finance_flag%22%3A%22-%22%2C%22platform%22%3A%221%22%2C%22version%22%3A1%2C%22client_ab%22%3A%22-%22%2C%22guid%22%3A%22440a8506-cc13-4f32-810a-e1c0c1a9d184%22%2C%22ca_city%22%3A%22xa%22%2C%22sessionid%22%3A%220d9d2a8b-da82-486a-9a7e-0853a22d0704%22%7D'
,'Referer': 'https://www.guazi.com/cs/buy/'
,'Host': 'www.guazi.com'
}

#获取详情页面url
def get_detail_urls(url):
    resp = requests.get(url, headers=headers)
    text = resp.content.decode('utf-8')
    html = etree.HTML(text)
    ul = html.xpath('//ul[@class="carlist clearfix js-top"]')[0]
    # print(ul)
    lis = ul.xpath('./li')
    detail_urls = []
    for li in lis:
        detail_url = li.xpath('./a/@href')
        detail_url = 'https://www.guazi.com' + detail_url[0]
        # print(detail_url)
        detail_urls.append(detail_url)
    return detail_urls

#解析详情页面内容
def parse_detail_page(url):
    resp = requests.get(url, headers=headers)
    text = resp.content.decode('utf-8')
    html = etree.HTML(text)
    title = html.xpath('//div[@class="product-textbox"]/h1/text()')
    title = ''.join(title).replace(r'\r\n', '').strip()
    # print(title)
    info = html.xpath('//div[@class="product-textbox"]/ul/li/span/text()')
    # print(info)
    infos = {}
    km = info[2]
    displacement = info[3]
    speedbox = info[4]

    infos['title'] = title
    infos['km'] = km
    infos['displacement'] = displacement
    infos['speedbox'] = speedbox
    return infos

#保存数据
def save_data(infos,f):
    f.write('{},{},{},{}\n'.format(infos['title'],infos['km'],infos['displacement'],infos['speedbox']))
    print(infos,"保存成功")


def main():
    #第一个url
    base_url = 'https://www.guazi.com/cs/buy/o{}/'
    with open('guaziershouche_cs.csv', 'a', encoding='utf-8') as f:
        for x in range(1,6):
            url = base_url.format(x)
            #获取详情页面url
            detail_urls = get_detail_urls(url)
            #解析详情页面内容
            for detail_url in detail_urls:
                infos = parse_detail_page(detail_url)
                save_data(infos,f)
                time.sleep(1)

if __name__ == '__main__':
    main()


